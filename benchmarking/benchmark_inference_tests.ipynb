{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Dipco/audio/dev/S02_U01.CH1.wav\n",
      "Processing Dipco/audio/dev/S04_U01.CH1.wav\n",
      "Processing Dipco/audio/dev/S05_U01.CH1.wav\n",
      "Processing Dipco/audio/dev/S09_U01.CH1.wav\n",
      "Processing Dipco/audio/dev/S10_U01.CH1.wav\n",
      "Processing Dipco/audio/eval/S01_U01.CH1.wav\n",
      "Processing Dipco/audio/eval/S03_U01.CH1.wav\n",
      "Processing Dipco/audio/eval/S06_U01.CH1.wav\n",
      "Processing Dipco/audio/eval/S07_U01.CH1.wav\n",
      "Processing Dipco/audio/eval/S08_U01.CH1.wav\n"
     ]
    }
   ],
   "source": [
    "# Converts wav files to spectrogram features which are saved to a specified file\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.lite.experimental.microfrontend.python.ops import audio_microfrontend_op as frontend_op \n",
    "\n",
    "wav_file_path = \"Dipco/audio/\"\n",
    "wav_file_glob = \"**/*U01.CH1.wav\"\n",
    "features_output_fname = 'dipco_features.npy'\n",
    "\n",
    "def generate_features_for_clip(clip_data):\n",
    "    micro_frontend = frontend_op.audio_microfrontend(\n",
    "        tf.convert_to_tensor(clip_data),\n",
    "        sample_rate=16000,\n",
    "        window_size=30,\n",
    "        window_step=20,\n",
    "        num_channels=40,\n",
    "        upper_band_limit=7500,\n",
    "        lower_band_limit=125,\n",
    "        enable_pcan=True,\n",
    "        min_signal_remaining=0.05,\n",
    "        out_scale=1,\n",
    "        out_type=tf.float32)\n",
    "    scaled = tf.multiply(micro_frontend, 0.0390625)\n",
    "    numpy = scaled.numpy()\n",
    "\n",
    "    return numpy\n",
    "\n",
    "clips = [str(i) for i in Path(wav_file_path).glob(wav_file_glob)]\n",
    "\n",
    "concatenated = False\n",
    "\n",
    "for clip in sorted(clips):\n",
    "    _,data = wav.read(clip)\n",
    "    padded_data = np.pad(data, (0,0),'constant',constant_values=(0,))\n",
    "    \n",
    "    print(\"Processing\", clip)\n",
    "    features = generate_features_for_clip(padded_data)\n",
    "\n",
    "    if not concatenated:\n",
    "      features_output = np.squeeze(features)\n",
    "      concatenated = True\n",
    "    else:\n",
    "      features_output = np.append(features_output, np.squeeze(features),axis=0)\n",
    "\n",
    "np.save(features_output_fname, features_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Given features data and a model, this computes the probability of the wakeword one stride at a time through all of the features and saves the probabilities to a file\n",
    "#  - The model can be quantized or not\n",
    "#  - The model can be streaming or nonstreaming\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "features_fname = 'dipco_features.npy'\n",
    "model_fname = '../trained_models/hey_jarvis/tflite_stream_state_external/stream_state_external.tflite'\n",
    "output_probabilities_fname = 'model_probabilities.npy'\n",
    "\n",
    "\n",
    "\n",
    "features_data = np.load(features_fname)\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=model_fname)\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "is_quantized_model = (input_details[0]['dtype'] == np.int8)\n",
    "input_feature_slices = input_details[0]['shape'][1]\n",
    "\n",
    "window_stride = 1\n",
    "start = 0\n",
    "end = input_feature_slices\n",
    "\n",
    "\n",
    "running_probability = []\n",
    "\n",
    "for s in range(len(input_details)):\n",
    "    if is_quantized_model:\n",
    "        interpreter.set_tensor(input_details[s]['index'], np.zeros(input_details[s]['shape'], dtype=np.int8))\n",
    "    else:\n",
    "        interpreter.set_tensor(input_details[s]['index'], np.zeros(input_details[s]['shape'], dtype=np.float32))\n",
    "\n",
    "def quantize_input_data(data, input_details):\n",
    "  \"\"\"quantize the input data using scale and zero point\n",
    "\n",
    "  Args:\n",
    "      data (np.array in float): input data for the interpreter\n",
    "      input_details : output of get_input_details from the tflm interpreter.\n",
    "\n",
    "  Returns:\n",
    "    np.ndarray: quantized data as int8 dtype\n",
    "  \"\"\"\n",
    "  # Get input quantization parameters\n",
    "  data_type = input_details['dtype']\n",
    "  \n",
    "  input_quantization_parameters = input_details['quantization_parameters']\n",
    "  input_scale, input_zero_point = input_quantization_parameters['scales'][\n",
    "      0], input_quantization_parameters['zero_points'][0]\n",
    "  # quantize the input data\n",
    "  data = data / input_scale + input_zero_point\n",
    "  return data.astype(data_type)\n",
    "\n",
    "def dequantize_output_data(data: np.ndarray,\n",
    "                           output_details: dict) -> np.ndarray:\n",
    "  \"\"\"Dequantize the model output\n",
    "\n",
    "  Args:\n",
    "      data: integer data to be dequantized\n",
    "      output_details: TFLM interpreter model output details\n",
    "\n",
    "  Returns:\n",
    "      np.ndarray: dequantized data as float32 dtype\n",
    "  \"\"\"\n",
    "  output_quantization_parameters = output_details['quantization_parameters']\n",
    "  output_scale = output_quantization_parameters['scales'][0]\n",
    "  output_zero_point = output_quantization_parameters['zero_points'][0]\n",
    "  # Caveat: tflm_output_quant need to be converted to float to avoid integer\n",
    "  # overflow during dequantization\n",
    "  # e.g., (tflm_output_quant -output_zero_point) and\n",
    "  # (tflm_output_quant + (-output_zero_point))\n",
    "  # can produce different results (int8 calculation)\n",
    "  return output_scale * (data.astype(np.float32) - output_zero_point)  \n",
    "\n",
    "while end < features_data.shape[0]:\n",
    "    new_data_to_input = features_data[start:end,:]\n",
    "    \n",
    "    if is_quantized_model:\n",
    "        new_data_to_input = quantize_input_data(new_data_to_input, input_details[0])\n",
    "    \n",
    "    # update indexes of streamed updates\n",
    "    start += window_stride\n",
    "    end += window_stride\n",
    "    \n",
    "    # Input new data and invoke the interpreter\n",
    "    interpreter.set_tensor(input_details[0]['index'], np.expand_dims(new_data_to_input,0))\n",
    "    interpreter.invoke()   \n",
    "\n",
    "    # get output states and feed them as inputs\n",
    "    # which will be fed in the next inference cycle for externally streaming models\n",
    "    for s in range(1,len(input_details)):\n",
    "        interpreter.set_tensor(input_details[s]['index'], interpreter.get_tensor(output_details[s]['index']))\n",
    "        \n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    if is_quantized_model:\n",
    "        wakeword_probability = dequantize_output_data(output[0][0], output_details[0])\n",
    "    else:\n",
    "        wakeword_probability = output[0][0]\n",
    "\n",
    "    running_probability.append(wakeword_probability)\n",
    "\n",
    "np.save(output_probabilities_fname, running_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False accept at frame 52556 ; timestamp 1050.92 s; probability 0.50478536\n",
      "False accepts per hour: 0.18745098937673585\n"
     ]
    }
   ],
   "source": [
    "# Takes in running probabilities and determines whether the model predicts the wake word or not\n",
    "# Computes false accept and false reject rates\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "probabilities_fname = 'model_probabilities.npy'\n",
    "label_fname = ''                        # label file with wake word timestamps generated by Picovoice's benchmark setup (https://github.com/Picovoice/wake-word-benchmark)\n",
    "probability_threshold = 0.5             # probability cutoff for wake word detection\n",
    "probabilities_sliding_window_size = 10  # how many probabilities in the sliding window that are averaged\n",
    "ignore_after_positive_setting = 74      # how many window strides after detecting the wake word to ignore before accepting the next wake word probability (currently, the model is built on spectrograms with 74 window strides)\n",
    "\n",
    "\n",
    "running_probability = np.load(probabilities_fname)\n",
    "probabilities_duration_h = running_probability.shape[0]*0.02/3600.0 # window stride is 0.02 s, dividing by 3600.0 to convert to hours\n",
    "\n",
    "ignore_after_positive = ignore_after_positive_setting\n",
    "true_accept = 0\n",
    "false_accept = 0\n",
    "\n",
    "keyword_times_sec = list()\n",
    "total_positive_phrases = 0\n",
    "labels = np.zeros((running_probability.shape[0],), dtype=bool)\n",
    "\n",
    "if label_fname != '':\n",
    "    with open(label_fname, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            keyword_times_sec.append(tuple(float(x) for x in line.strip('\\n').split(', ')))\n",
    "\n",
    "    total_positive_phrases = len(keyword_times_sec)\n",
    "\n",
    "    # Using Picovoice's benchmark setup https://github.com/Picovoice/wake-word-benchmark\n",
    "    for start_sec, end_sec in keyword_times_sec:\n",
    "        start_frame = int(start_sec//0.02)\n",
    "        end_frame = int((end_sec//0.02))\n",
    "        labels[start_frame:(end_frame + 1)] = True\n",
    "\n",
    "def running_average_detection(window_probabilities, threshold):\n",
    "    return np.average(window_probabilities) > threshold\n",
    "\n",
    "for index in range(0, running_probability.shape[0]):\n",
    "    if ignore_after_positive > 0:\n",
    "        ignore_after_positive -= 1\n",
    "    else:\n",
    "        detected = running_average_detection(running_probability[index-probabilities_sliding_window_size:index], probability_threshold)\n",
    "        \n",
    "        if detected:\n",
    "            ignore_after_positive = ignore_after_positive_setting\n",
    "            if labels[index-probabilities_sliding_window_size]:\n",
    "                true_accept += 1\n",
    "            else:\n",
    "                false_accept += 1\n",
    "                print(\"False accept at frame\", index, \"; timestamp\", ((index-probabilities_sliding_window_size)*0.02), \"s; probability\", (np.average(running_probability[index-probabilities_sliding_window_size:index])))\n",
    "                \n",
    "                \n",
    "if total_positive_phrases > 0:\n",
    "    print(\"False reject rate:\", (total_positive_phrases-true_accept)/total_positive_phrases)\n",
    "print(\"False accepts per hour:\", false_accept/probabilities_duration_h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
