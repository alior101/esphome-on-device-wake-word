{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "import pandas as pd\n",
    "import collections\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.lite.experimental.microfrontend.python.ops import audio_microfrontend_op as frontend_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_for_clip(clip):\n",
    "    micro_frontend = frontend_op.audio_microfrontend(\n",
    "        tf.convert_to_tensor(clip),\n",
    "        sample_rate=16000,\n",
    "        window_size=30,\n",
    "        window_step=20,\n",
    "        num_channels=40,\n",
    "        upper_band_limit=7500,\n",
    "        lower_band_limit=125,\n",
    "        enable_pcan=True,\n",
    "        min_signal_remaining=0.05,\n",
    "        out_scale=1,\n",
    "        out_type=tf.float32)\n",
    "    output = tf.multiply(micro_frontend, 0.0390625)\n",
    "    return output.numpy()\n",
    "\n",
    "def features_generator(generator):\n",
    "    for data in generator:\n",
    "        for clip in data:\n",
    "            yield generate_features_for_clip(clip)\n",
    "\n",
    "infer_model = tf.lite.Interpreter(model_path=\"./stream_state_internal_quantize.tflite\", num_threads=1)\n",
    "infer_model.resize_tensor_input(0, [1,1,40], strict=True)  # initialize with fixed input size\n",
    "infer_model.allocate_tensors()\n",
    "input_details = infer_model.get_input_details()\n",
    "output_details = infer_model.get_output_details()\n",
    "print()\n",
    "print(\"Input details:\")\n",
    "print(input_details)\n",
    "print()\n",
    "print(\"Output details:\")\n",
    "print(output_details)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define function to process audio\n",
    "def process_audio(audio, state=collections.defaultdict(partial(collections.deque, maxlen=60))):\n",
    "    # Resample audio to 16khz if needed\n",
    "    if audio[0] != 16000:\n",
    "        data = scipy.signal.resample(audio[1], int(float(audio[1].shape[0])/audio[0]*16000))\n",
    "\n",
    "    data = data.astype(np.int16)\n",
    "    print(data.shape)\n",
    "    res = generate_features_for_clip(data)\n",
    "    # Get predictions\n",
    "    for row in res:\n",
    "        row1 = row.astype(np.int8)\n",
    "        row2 = row1.reshap([1,1,40])\n",
    "        infer_model.set_tensor(input_details[0]['index'], row1)\n",
    "        infer_model.invoke()\n",
    "        pred = infer_model.get_tensor(output_details[0]['index'])\n",
    "        print(pred)\n",
    "        # for key in prediction:\n",
    "        #     #Fill deque with zeros if it's empty\n",
    "        #     if len(state[key]) == 0:\n",
    "        #         state[key].extend(np.zeros(60))\n",
    "\n",
    "        #     # Add prediction\n",
    "        #     state[key].append(prediction[key])\n",
    "\n",
    "        # if len(data.shape) == 2 or data.shape[-1] == 2:\n",
    "        #     chunk = data[i:i+40][:, 0]  # just get one channel of audio\n",
    "        # else:\n",
    "        #     chunk = data[i:i+40]\n",
    "\n",
    "        # if chunk.shape[0] == 40:\n",
    "        #     prediction = infer_model.predict(row)\n",
    "        #     for key in prediction:\n",
    "        #         #Fill deque with zeros if it's empty\n",
    "        #         if len(state[key]) == 0:\n",
    "        #             state[key].extend(np.zeros(60))\n",
    "\n",
    "        #         # Add prediction\n",
    "        #         state[key].append(prediction[key])\n",
    "\n",
    "    # Make line plot\n",
    "    dfs = []\n",
    "    for key in state.keys():\n",
    "        df = pd.DataFrame({\"x\": np.arange(len(state[key])), \"y\": state[key], \"Model\": key})\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    plot = gr.LinePlot().update(value = df, x='x', y='y', color=\"Model\", y_lim = (0,1), tooltip=\"Model\",\n",
    "                                width=600, height=300, x_title=\"Time (frames)\", y_title=\"Model Score\", color_legend_position=\"bottom\")\n",
    "\n",
    "    # Manually adjust how the legend is displayed\n",
    "    tmp = json.loads(plot[\"value\"][\"plot\"])\n",
    "    tmp[\"layer\"][0]['encoding']['color']['legend'][\"direction\"] = \"vertical\"\n",
    "    tmp[\"layer\"][0]['encoding']['color']['legend'][\"columns\"] = 4\n",
    "    tmp[\"layer\"][0]['encoding']['color']['legend'][\"labelFontSize\"] = 12\n",
    "    tmp[\"layer\"][0]['encoding']['color']['legend'][\"titleFontSize\"] = 14\n",
    "\n",
    "    plot[\"value\"]['plot'] = json.dumps(tmp)\n",
    "\n",
    "    return plot, state\n",
    "\n",
    "# Create Gradio interface and launch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = \"\"\"\n",
    "This is a test of the pre-trained models\n",
    "\"\"\"\n",
    "\n",
    "gr_int = gr.Interface(\n",
    "    title = \"openWakeWord Live Demo\",\n",
    "    description = desc,\n",
    "    css = \".flex {flex-direction: column} .gr-panel {width: 100%}\",\n",
    "    fn=process_audio,\n",
    "    inputs=[\n",
    "        gr.Audio(sources=[\"microphone\"], type=\"numpy\", streaming=True, show_label=False),\n",
    "        #gr.Audio(source=[\"microphone\"], type=\"numpy\", streaming=True, show_label=False),\n",
    "        \"state\"\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.LinePlot(show_label=False),\n",
    "        \"state\"\n",
    "    ],\n",
    "    live=True)\n",
    "\n",
    "gr_int.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
