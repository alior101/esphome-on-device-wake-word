{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXYgXFeMgRep"
      },
      "source": [
        "Copyright 2019 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcIzzCADklYm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/google-research/google-research.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ngihcW7ckrDI"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "import zipfile\n",
        "sys.path.append('/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y55h79H3XKSt"
      },
      "source": [
        "# Example of model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw1HFRd-UcTk"
      },
      "source": [
        "Below steps are taken from [model_train_eval](https://github.com/google-research/google-research/blob/master/kws_streaming/train/model_train_eval.py) - it has more tests in streaming, non streaming, quantized and non qunatized models with TF and TFLite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fathHzuEgx8_"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yP5WBy5O8Za8"
      },
      "outputs": [],
      "source": [
        "# TF streaming\n",
        "from kws_streaming.models import models\n",
        "from kws_streaming.models import utils\n",
        "from kws_streaming.layers.modes import Modes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wsUCmBzpk1jC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/.venv/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as nppip\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import logging\n",
        "from kws_streaming.models import model_flags\n",
        "from kws_streaming.models import model_params\n",
        "from kws_streaming.train import test\n",
        "from kws_streaming.train import train\n",
        "from kws_streaming import data\n",
        "tf1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RS8tH1UvUcTu"
      },
      "outputs": [],
      "source": [
        "config = tf1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf1.Session(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zMdTK10tL2Dz"
      },
      "outputs": [],
      "source": [
        "# general imports\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import scipy as scipy\n",
        "import scipy.io.wavfile as wav\n",
        "import scipy.signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PMti09MMUcT2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.13.1'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xHTcbg_ao586"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/.venv/lib/python3.10/site-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tf1.reset_default_graph()\n",
        "sess = tf1.Session()\n",
        "tf1.keras.backend.set_session(sess)\n",
        "tf1.keras.backend.set_learning_phase(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylPGCTPLh41F"
      },
      "source": [
        "## Set path to data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eEg-24R5UcT_"
      },
      "outputs": [],
      "source": [
        "# set PATH to data sets (for example to speech commands V2):\n",
        "# it can be downloaded from\n",
        "# https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
        "# if you already run \"00_check-data.ipynb\" then folder \"data2\" should be located in the current dir\n",
        "current_dir = os.getcwd()\n",
        "DATA_PATH = '/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OObn08smUcUC"
      },
      "outputs": [],
      "source": [
        "def waveread_as_pcm16(filename):\n",
        "  \"\"\"Read in audio data from a wav file.  Return d, sr.\"\"\"\n",
        "  samplerate, wave_data = wav.read(filename)\n",
        "  # Read in wav file.\n",
        "  return wave_data, samplerate\n",
        "\n",
        "def wavread_as_float(filename, target_sample_rate=16000):\n",
        "  \"\"\"Read in audio data from a wav file.  Return d, sr.\"\"\"\n",
        "  wave_data, samplerate = waveread_as_pcm16(filename)\n",
        "  desired_length = int(\n",
        "          round(float(len(wave_data)) / samplerate * target_sample_rate))\n",
        "  wave_data = scipy.signal.resample(wave_data, desired_length)\n",
        "\n",
        "  # Normalize short ints to floats in range [-1..1).\n",
        "  data = np.array(wave_data, np.float32) / 32768.0\n",
        "  return data, target_sample_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYj0JGeHhtqc"
      },
      "outputs": [],
      "source": [
        "# Set path to wav file to visualize it\n",
        "wav_file = os.path.join(DATA_PATH, \"left/012187a4_nohash_0.wav\")\n",
        "\n",
        "# read audio file\n",
        "wav_data, samplerate = wavread_as_float(wav_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cLAd9tfiUcUK"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'samplerate' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/01_train.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/01_train.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m samplerate \u001b[39m==\u001b[39m \u001b[39m16000\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'samplerate' is not defined"
          ]
        }
      ],
      "source": [
        "assert samplerate == 16000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2yeKkLsiRWJ"
      },
      "outputs": [],
      "source": [
        "plt.plot(wav_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_wbAZ3vhQh1"
      },
      "source": [
        "## Set path to a model with config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3Ligfp0KUcUV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['svdf', 'svdf_resnet', 'ds_cnn', 'gru', 'lstm', 'cnn_stride', 'cnn', 'tc_resnet', 'crnn', 'dnn', 'att_rnn', 'att_mh_rnn', 'mobilenet', 'mobilenet_v2', 'xception', 'inception', 'inception_resnet', 'ds_tc_resnet', 'bc_resnet'])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# select model name should be one of\n",
        "model_params.HOTWORD_MODEL_PARAMS.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "04bbXWx2UcUa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/models/ds_tc_resnet/'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This notebook is configured to work with 'ds_tc_resnet' and 'svdf'.\n",
        "MODEL_NAME = 'ds_tc_resnet'\n",
        "# MODEL_NAME = 'svdf'\n",
        "MODELS_PATH = os.path.join(current_dir, \"models\")\n",
        "MODEL_PATH = os.path.join(MODELS_PATH, MODEL_NAME + \"/\")\n",
        "MODEL_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "l9sn53qfUcUd"
      },
      "outputs": [
        {
          "ename": "FileExistsError",
          "evalue": "[Errno 17] File exists: '/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/models/ds_tc_resnet/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;32m/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/01_train.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/01_train.ipynb#Y106sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# delete previously trained model with its folder and create a new one:\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/01_train.ipynb#Y106sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39;49mmakedirs(MODEL_PATH)\n",
            "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.12_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/models/ds_tc_resnet/'"
          ]
        }
      ],
      "source": [
        "# delete previously trained model with its folder and create a new one:\n",
        "os.makedirs(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OBHIwG8FUcUg"
      },
      "outputs": [],
      "source": [
        "# get toy model settings\n",
        "FLAGS = model_params.HOTWORD_MODEL_PARAMS[MODEL_NAME]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6z7ZVz3dUcUl"
      },
      "outputs": [],
      "source": [
        "FLAGS.wanted_words = \"computer\"\n",
        "# set path to data and model (where model will be stored)\n",
        "FLAGS.data_dir = DATA_PATH\n",
        "FLAGS.train_dir = MODEL_PATH\n",
        "\n",
        "# set speech feature extractor properties\n",
        "FLAGS.mel_upper_edge_hertz = 7600\n",
        "FLAGS.window_size_ms = 30.0\n",
        "FLAGS.window_stride_ms = 20.0\n",
        "FLAGS.mel_num_bins = 80\n",
        "FLAGS.dct_num_features = 40\n",
        "FLAGS.feature_type = 'mfcc_tf'\n",
        "FLAGS.preprocess = 'micro'\n",
        "FLAGS.micro_enable_pcan = True\n",
        "FLAGS.micro_min_signal_remaining = 0.05\n",
        "FLAGS.micro_out_scale = 1\n",
        "FLAGS.micro_features_scale = 10.0/256.0\n",
        "\n",
        "# for numerical correctness of streaming and non streaming models set it to 1\n",
        "# but for real use case streaming set it to 0\n",
        "FLAGS.causal_data_frame_padding = 0\n",
        "\n",
        "FLAGS.use_tf_fft = True\n",
        "FLAGS.mel_non_zero_only = not FLAGS.use_tf_fft\n",
        "\n",
        "# set training settings\n",
        "FLAGS.train = 1\n",
        "# reduced number of training steps for test only\n",
        "# so model accuracy will be low,\n",
        "# to improve accuracy set how_many_training_steps = '40000,40000,20000,20000'\n",
        "FLAGS.how_many_training_steps = '400,400,400,400'\n",
        "FLAGS.learning_rate = '0.001,0.0005,0.0001,0.00002'\n",
        "FLAGS.lr_schedule = 'linear'\n",
        "FLAGS.verbosity = logging.INFO\n",
        "\n",
        "# data augmentation parameters\n",
        "FLAGS.resample = 0.15\n",
        "FLAGS.time_shift_ms = 100\n",
        "FLAGS.use_spec_augment = 1\n",
        "FLAGS.time_masks_number = 2\n",
        "FLAGS.time_mask_max_size = 25\n",
        "FLAGS.frequency_masks_number = 2\n",
        "FLAGS.frequency_mask_max_size = 7\n",
        "FLAGS.pick_deterministically = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "sL8zW5ADUcUp"
      },
      "outputs": [],
      "source": [
        "FLAGS.model_name = MODEL_NAME\n",
        "\n",
        "# model parameters are different for every model\n",
        "if MODEL_NAME == 'svdf':\n",
        "  FLAGS.model_name = MODEL_NAME\n",
        "  FLAGS.svdf_memory_size = \"4,10,10,10,10,10\"\n",
        "  FLAGS.svdf_units1 = \"16,32,32,32,64,128\"\n",
        "  FLAGS.svdf_act = \"'relu','relu','relu','relu','relu','relu'\"\n",
        "  FLAGS.svdf_units2 = \"40,40,64,64,64,-1\"\n",
        "  FLAGS.svdf_dropout = \"0.0,0.0,0.0,0.0,0.0,0.0\"\n",
        "  FLAGS.svdf_pad = 0\n",
        "  FLAGS.dropout1 = 0.0\n",
        "  FLAGS.units2 = ''\n",
        "  FLAGS.act2 = ''\n",
        "elif MODEL_NAME == 'ds_tc_resnet':\n",
        "  # it is an example of model streaming with strided convolution, strided pooling and dilated convolution\n",
        "  FLAGS.activation = 'relu'\n",
        "  FLAGS.dropout = 0.0\n",
        "  FLAGS.ds_filters = '128, 64, 64, 64, 128, 128'\n",
        "  FLAGS.ds_filter_separable = '1, 1, 1, 1, 1, 1'\n",
        "  FLAGS.ds_repeat = '1, 1, 1, 1, 1, 1'\n",
        "  FLAGS.ds_residual = '0, 1, 1, 1, 0, 0' # residual can not be applied with stride\n",
        "#   FLAGS.ds_kernel_size = '11, 5, 15, 7, 29, 1'\n",
        "  FLAGS.ds_kernel_size = '11, 5, 15, 17, 15, 1'\n",
        "  FLAGS.ds_dilation = '1, 1, 1, 1, 2, 1'\n",
        "  FLAGS.ds_stride = '1, 1, 1, 1, 1, 1'\n",
        "  FLAGS.ds_pool = '1, 2, 1, 1, 1, 1'\n",
        "  # model should be causal, so that we can covert it to streaming mode\n",
        "  # if model is non causal then all non causal components should use Delay layer\n",
        "  FLAGS.ds_padding = \"'causal', 'causal', 'causal', 'causal', 'causal', 'causal'\"\n",
        "else:\n",
        "  raise ValueError(\"set parameters for other models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "W7gI-9jTzb7M"
      },
      "outputs": [],
      "source": [
        "FLAGS.clip_duration_ms = 1000  # standard audio file in this data set has 1 sec length\n",
        "FLAGS.batch_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Tt6a1m8RUcUs"
      },
      "outputs": [],
      "source": [
        "flags = model_flags.update_flags(FLAGS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7vXrn3szUcUy"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(flags.train_dir, 'flags.json'), 'wt') as f:\n",
        "  json.dump(flags.__dict__, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8GWgpluSUcU1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-18 16:04:47.642244: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "WARNING:absl:There is no need to use Stream on time dim with size 1: depthwise_conv2d_5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
          ]
        }
      ],
      "source": [
        "# visualize a model\n",
        "model_non_stream_batch = models.MODELS[flags.model_name](flags)\n",
        "tf.keras.utils.plot_model(\n",
        "    model_non_stream_batch,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PGbLrABNUcU5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(100, 49, 80)]              0         []                            \n",
            "                                                                                                  \n",
            " tf_op_layer_ExpandDims (Te  [(100, 49, 1, 80)]           0         ['input_1[0][0]']             \n",
            " nsorFlowOpLayer)                                                                                 \n",
            "                                                                                                  \n",
            " stream (Stream)             (100, 49, 1, 80)             880       ['tf_op_layer_ExpandDims[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (100, 49, 1, 128)            10240     ['stream[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (100, 49, 1, 128)            512       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (100, 49, 1, 128)            0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (100, 49, 1, 128)            0         ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " stream_1 (Stream)           (100, 49, 1, 128)            640       ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (100, 49, 1, 64)             8192      ['stream_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (100, 49, 1, 64)             8192      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (100, 49, 1, 64)             256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (100, 49, 1, 64)             256       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (100, 49, 1, 64)             0         ['batch_normalization_1[0][0]'\n",
            "                                                                    , 'batch_normalization_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (100, 49, 1, 64)             0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (100, 49, 1, 64)             0         ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (100, 24, 1, 64)             0         ['dropout_1[0][0]']           \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " stream_2 (Stream)           (100, 24, 1, 64)             960       ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (100, 24, 1, 64)             4096      ['stream_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (100, 24, 1, 64)             4096      ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (100, 24, 1, 64)             256       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (100, 24, 1, 64)             256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (100, 24, 1, 64)             0         ['batch_normalization_3[0][0]'\n",
            "                                                                    , 'batch_normalization_4[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (100, 24, 1, 64)             0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (100, 24, 1, 64)             0         ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " stream_3 (Stream)           (100, 24, 1, 64)             1088      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (100, 24, 1, 64)             4096      ['stream_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (100, 24, 1, 64)             4096      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (100, 24, 1, 64)             256       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (100, 24, 1, 64)             256       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (100, 24, 1, 64)             0         ['batch_normalization_5[0][0]'\n",
            "                                                                    , 'batch_normalization_6[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (100, 24, 1, 64)             0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (100, 24, 1, 64)             0         ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " stream_4 (Stream)           (100, 24, 1, 64)             960       ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (100, 24, 1, 128)            8192      ['stream_4[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (100, 24, 1, 128)            512       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (100, 24, 1, 128)            0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (100, 24, 1, 128)            0         ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " stream_5 (Stream)           (100, 24, 1, 128)            128       ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (100, 24, 1, 128)            16384     ['stream_5[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (100, 24, 1, 128)            512       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (100, 24, 1, 128)            0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (100, 24, 1, 128)            0         ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " stream_6 (Stream)           (100, 128)                   0         ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (100, 128)                   0         ['stream_6[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)               (100, 3)                     387       ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 75699 (295.70 KB)\n",
            "Trainable params: 74163 (289.70 KB)\n",
            "Non-trainable params: 1536 (6.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_non_stream_batch.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc3yteQJUcU8"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "EXSDOpQ_UcU9"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Params' object has no attribute 'micro_features_scale'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/01_train.ipynb Cell 32\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/01_train.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Model training\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kahrendt/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/colab/01_train.ipynb#Y122sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train\u001b[39m.\u001b[39;49mtrain(flags)\n",
            "File \u001b[0;32m~/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/train/train.py:54\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(flags)\u001b[0m\n\u001b[1;32m     51\u001b[0m sess \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mSession(config\u001b[39m=\u001b[39mconfig)\n\u001b[1;32m     52\u001b[0m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mset_session(sess)\n\u001b[0;32m---> 54\u001b[0m audio_processor \u001b[39m=\u001b[39m input_data\u001b[39m.\u001b[39;49mAudioProcessor(flags)\n\u001b[1;32m     56\u001b[0m time_shift_samples \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((flags\u001b[39m.\u001b[39mtime_shift_ms \u001b[39m*\u001b[39m flags\u001b[39m.\u001b[39msample_rate) \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[39m# Figure out the learning rates for each training phase. Since it's often\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# effective to have high learning rates at the start of training, followed by\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m# lower levels towards the end, the number of steps and learning rates can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m# will run 13,000 training loops in total, with a rate of 0.001 for the first\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m# 10,000, and 0.0001 for the final 3,000.\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/data/input_data.py:127\u001b[0m, in \u001b[0;36mAudioProcessor.__init__\u001b[0;34m(self, flags)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_split_data_index(wanted_words, flags\u001b[39m.\u001b[39msplit_data, file_ext)\n\u001b[1;32m    126\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_background_data()\n\u001b[0;32m--> 127\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_processing_graph(flags)\n",
            "File \u001b[0;32m~/Documents/Hobbies/Machine_Learning/wakeword_tflite/kws_streaming/data/input_data.py:533\u001b[0m, in \u001b[0;36mAudioProcessor.prepare_processing_graph\u001b[0;34m(self, flags)\u001b[0m\n\u001b[1;32m    520\u001b[0m   micro_frontend \u001b[39m=\u001b[39m frontend_op\u001b[39m.\u001b[39maudio_microfrontend(\n\u001b[1;32m    521\u001b[0m       int16_input,\n\u001b[1;32m    522\u001b[0m       sample_rate\u001b[39m=\u001b[39mflags\u001b[39m.\u001b[39msample_rate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m       out_scale\u001b[39m=\u001b[39mflags\u001b[39m.\u001b[39mmicro_out_scale,\n\u001b[1;32m    531\u001b[0m       out_type\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m    532\u001b[0m   \u001b[39m# int16_input dims: [frames, num_channels]\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_ \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmultiply(micro_frontend, flags\u001b[39m.\u001b[39;49mmicro_features_scale)\n\u001b[1;32m    534\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnknown preprocess mode \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m (should be \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    536\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmfcc\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (flags\u001b[39m.\u001b[39mpreprocess))\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Params' object has no attribute 'micro_features_scale'"
          ]
        }
      ],
      "source": [
        "# Model training\n",
        "train.train(flags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIr1DWLisMu9"
      },
      "source": [
        "## Run model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "456ynjRxmdVc"
      },
      "source": [
        "### TF Run non streaming inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e_X-fKdUcVC"
      },
      "outputs": [],
      "source": [
        "folder_name = 'tf'\n",
        "test.tf_non_stream_model_accuracy(flags, folder_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dyT1fQcUcVF"
      },
      "source": [
        "more testing functions can be found at [test](https://github.com/google-research/google-research/blob/master/kws_streaming/train/test.py)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "01_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
